{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:absl:module 'tensorflow_datasets.core' has no attribute 'utils'\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\bpadmin\\anaconda3\\envs\\tensorflow_cuda\\lib\\site-packages\\tensorflow_datasets\\__init__.py\", line 59, in <module>\n",
      "    from tensorflow_datasets import audio\n",
      "  File \"c:\\Users\\bpadmin\\anaconda3\\envs\\tensorflow_cuda\\lib\\site-packages\\tensorflow_datasets\\audio\\__init__.py\", line 19, in <module>\n",
      "    from tensorflow_datasets.audio.commonvoice import CommonVoice\n",
      "  File \"c:\\Users\\bpadmin\\anaconda3\\envs\\tensorflow_cuda\\lib\\site-packages\\tensorflow_datasets\\audio\\commonvoice.py\", line 27, in <module>\n",
      "    import tensorflow_datasets.public_api as tfds\n",
      "  File \"c:\\Users\\bpadmin\\anaconda3\\envs\\tensorflow_cuda\\lib\\site-packages\\tensorflow_datasets\\public_api.py\", line 57, in <module>\n",
      "    deprecated = core.utils.docs.deprecated(deprecated)\n",
      "AttributeError: module 'tensorflow_datasets.core' has no attribute 'utils'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "import tensorflow_recommenders as tfrs \n",
    "import tensorflow_datasets as tfds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tfds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ratings \u001b[38;5;241m=\u001b[39m \u001b[43mtfds\u001b[49m\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmovielens/100k-ratings\u001b[39m\u001b[38;5;124m\"\u001b[39m, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m movies \u001b[38;5;241m=\u001b[39m tfds\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmovielens/100k-movies\u001b[39m\u001b[38;5;124m\"\u001b[39m, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tfds' is not defined"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "\n",
    "ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
    "movies = tfds.load(\"movielens/100k-movies\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings.map(lambda x: {\n",
    "    \"movie_title\": x[\"movie_title\"],\n",
    "    \"user_id\": x[\"user_id\"],\n",
    "    \"timestamp\": x[\"timestamp\"],\n",
    "})\n",
    "\n",
    "movies = movies.map(lambda x: x[\"movie_title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = np.concatenate(list(ratings.map(lambda x: x[\"timestamp\"]).batch(100)))\n",
    "\n",
    "max_timestamp = timestamps.max()\n",
    "min_timestamp = timestamps.min()\n",
    "\n",
    "timestamp_buckets = np.linspace(\n",
    "    min_timestamp, max_timestamp, num=1000,\n",
    ")\n",
    "\n",
    "unique_movie_titles = np.unique(np.concatenate(list(movies.batch(1000))))\n",
    "unique_user_ids = np.unique(np.concatenate(list(ratings.batch(1_000).map(\n",
    "    lambda x: x[\"user_id\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "steps:\n",
    "1. preprocessing\n",
    "2. define query and candidate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'movie_genres': array([4], dtype=int64),\n",
       " 'movie_id': b'1681',\n",
       " 'movie_title': b'You So Crazy (1994)'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(movies.take(1).as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bucketized_user_age': 45.0,\n",
       " 'movie_genres': array([7], dtype=int64),\n",
       " 'movie_id': b'357',\n",
       " 'movie_title': b\"One Flew Over the Cuckoo's Nest (1975)\",\n",
       " 'raw_user_age': 46.0,\n",
       " 'timestamp': 879024327,\n",
       " 'user_gender': True,\n",
       " 'user_id': b'138',\n",
       " 'user_occupation_label': 4,\n",
       " 'user_occupation_text': b'doctor',\n",
       " 'user_rating': 4.0,\n",
       " 'user_zip_code': b'53211'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(ratings.take(1).as_numpy_iterator())\n",
    "# next((ratings.map(lambda x: x['movie_id'] == '1681')).take(1).as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UserModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self, use_timestamps):\n",
    "    super().__init__()\n",
    "\n",
    "    self._use_timestamps = use_timestamps\n",
    "\n",
    "    self.user_embedding = tf.keras.Sequential([\n",
    "        tf.keras.layers.StringLookup(\n",
    "            vocabulary=unique_user_ids, mask_token=None),\n",
    "        tf.keras.layers.Embedding(len(unique_user_ids) + 1, 32),\n",
    "    ])\n",
    "\n",
    "    if use_timestamps:\n",
    "      self.timestamp_embedding = tf.keras.Sequential([\n",
    "          tf.keras.layers.Discretization(timestamp_buckets.tolist()),\n",
    "          tf.keras.layers.Embedding(len(timestamp_buckets) + 1, 32),\n",
    "      ])\n",
    "      self.normalized_timestamp = tf.keras.layers.Normalization(\n",
    "          axis=None\n",
    "      )\n",
    "\n",
    "      self.normalized_timestamp.adapt(timestamps)\n",
    "\n",
    "\n",
    "  def call(self, inputs):\n",
    "    if not self._use_timestamps:\n",
    "      return self.user_embedding(inputs[\"user_id\"])\n",
    "\n",
    "    return tf.concat([\n",
    "        self.user_embedding(inputs[\"user_id\"]),\n",
    "        self.timestamp_embedding(inputs[\"timestamp\"]),\n",
    "        tf.reshape(self.normalized_timestamp(inputs[\"timestamp\"]), (-1, 1)), \n",
    "    ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ItemModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    max_tokens = 10_000\n",
    "\n",
    "    self.title_embedding = tf.keras.Sequential([\n",
    "      tf.keras.layers.StringLookup(\n",
    "          vocabulary=unique_movie_titles, mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(unique_movie_titles) + 1, 32)\n",
    "    ])\n",
    "\n",
    "    self.title_vectorizer = tf.keras.layers.TextVectorization(\n",
    "        max_tokens=max_tokens)\n",
    "\n",
    "    self.title_text_embedding = tf.keras.Sequential([\n",
    "      self.title_vectorizer,\n",
    "      tf.keras.layers.Embedding(max_tokens, 32, mask_zero=True),\n",
    "      tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    ])\n",
    "    \n",
    "    self.title_vectorizer.adapt(movies)\n",
    "\n",
    "  def call(self, titles):\n",
    "    return tf.concat([\n",
    "        self.title_embedding(titles),\n",
    "        self.title_text_embedding(titles),\n",
    "    ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# recommender model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovielensModel(tfrs.models.Model):\n",
    "\n",
    "  def __init__(self, use_timestamps):\n",
    "    super().__init__()\n",
    "    self.query_model = tf.keras.Sequential([\n",
    "      UserModel(use_timestamps),\n",
    "      tf.keras.layers.Dense(32)\n",
    "    ])\n",
    "    self.candidate_model = tf.keras.Sequential([\n",
    "      MovieModel(),\n",
    "      tf.keras.layers.Dense(32)\n",
    "    ])\n",
    "    self.task = tfrs.tasks.Retrieval(\n",
    "        metrics=tfrs.metrics.FactorizedTopK(\n",
    "            candidates=movies.batch(128).map(self.candidate_model),\n",
    "            # ks = [10]\n",
    "        ),\n",
    "    )\n",
    "\n",
    "  def compute_loss(self, features, training=False):\n",
    "    # We only pass the user id and timestamp features into the query model. This\n",
    "    # is to ensure that the training inputs would have the same keys as the\n",
    "    # query inputs. Otherwise the discrepancy in input structure would cause an\n",
    "    # error when loading the query model after saving it.\n",
    "    query_embeddings = self.query_model({\n",
    "        \"user_id\": features[\"user_id\"],\n",
    "        \"timestamp\": features[\"timestamp\"],\n",
    "    })\n",
    "    movie_embeddings = self.candidate_model(features[\"movie_title\"])\n",
    "\n",
    "    return self.task(query_embeddings, movie_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(80_000)\n",
    "test = shuffled.skip(80_000).take(20_000)\n",
    "\n",
    "cached_train = train.shuffle(100_000).batch(2048)\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movie_title': b'Postman, The (1997)',\n",
      " 'timestamp': 885409515,\n",
      " 'user_id': b'681'}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(next(train.take(1).as_numpy_iterator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'user_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'timestamp': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=int64>}. Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'user_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'timestamp': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=int64>}. Consider rewriting this model with the Functional API.\n",
      "40/40 [==============================] - 6s 117ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0150 - factorized_top_k/top_5_categorical_accuracy: 0.0272 - factorized_top_k/top_10_categorical_accuracy: 0.0371 - factorized_top_k/top_50_categorical_accuracy: 0.0955 - factorized_top_k/top_100_categorical_accuracy: 0.1596 - loss: 14570.5523 - regularization_loss: 0.0000e+00 - total_loss: 14570.5523\n",
      "Epoch 2/3\n",
      "40/40 [==============================] - 5s 121ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0033 - factorized_top_k/top_5_categorical_accuracy: 0.0153 - factorized_top_k/top_10_categorical_accuracy: 0.0276 - factorized_top_k/top_50_categorical_accuracy: 0.1232 - factorized_top_k/top_100_categorical_accuracy: 0.2278 - loss: 14120.1746 - regularization_loss: 0.0000e+00 - total_loss: 14120.1746\n",
      "Epoch 3/3\n",
      "40/40 [==============================] - 5s 114ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0024 - factorized_top_k/top_5_categorical_accuracy: 0.0160 - factorized_top_k/top_10_categorical_accuracy: 0.0330 - factorized_top_k/top_50_categorical_accuracy: 0.1462 - factorized_top_k/top_100_categorical_accuracy: 0.2594 - loss: 13922.1723 - regularization_loss: 0.0000e+00 - total_loss: 13922.1723\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'user_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'timestamp': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=int64>}. Consider rewriting this model with the Functional API.\n",
      "40/40 [==============================] - 5s 117ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0028 - factorized_top_k/top_5_categorical_accuracy: 0.0239 - factorized_top_k/top_10_categorical_accuracy: 0.0472 - factorized_top_k/top_50_categorical_accuracy: 0.1896 - factorized_top_k/top_100_categorical_accuracy: 0.3160 - loss: 13678.5855 - regularization_loss: 0.0000e+00 - total_loss: 13678.5855\n",
      "5/5 [==============================] - 1s 172ms/step - factorized_top_k/top_1_categorical_accuracy: 4.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0082 - factorized_top_k/top_10_categorical_accuracy: 0.0183 - factorized_top_k/top_50_categorical_accuracy: 0.1185 - factorized_top_k/top_100_categorical_accuracy: 0.2253 - loss: 31006.9668 - regularization_loss: 0.0000e+00 - total_loss: 31006.9668\n",
      "Top-100 accuracy (train): 0.32.\n",
      "Top-100 accuracy (test): 0.23.\n"
     ]
    }
   ],
   "source": [
    "model = MovielensModel(use_timestamps=False)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
    "\n",
    "model.fit(cached_train, epochs=3)\n",
    "\n",
    "train_accuracy = model.evaluate(\n",
    "    cached_train, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"]\n",
    "\n",
    "test_accuracy = model.evaluate(\n",
    "    cached_test, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"]\n",
    "\n",
    "print(f\"Top-100 accuracy (train): {train_accuracy:.2f}.\")\n",
    "print(f\"Top-100 accuracy (test): {test_accuracy:.2f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'user_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'timestamp': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=int64>}. Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'user_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'timestamp': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=int64>}. Consider rewriting this model with the Functional API.\n",
      "40/40 [==============================] - 6s 115ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0110 - factorized_top_k/top_5_categorical_accuracy: 0.0231 - factorized_top_k/top_10_categorical_accuracy: 0.0333 - factorized_top_k/top_50_categorical_accuracy: 0.0956 - factorized_top_k/top_100_categorical_accuracy: 0.1626 - loss: 14533.5506 - regularization_loss: 0.0000e+00 - total_loss: 14533.5506\n",
      "Epoch 2/3\n",
      "40/40 [==============================] - 5s 116ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0034 - factorized_top_k/top_5_categorical_accuracy: 0.0175 - factorized_top_k/top_10_categorical_accuracy: 0.0341 - factorized_top_k/top_50_categorical_accuracy: 0.1442 - factorized_top_k/top_100_categorical_accuracy: 0.2621 - loss: 13937.2593 - regularization_loss: 0.0000e+00 - total_loss: 13937.2593\n",
      "Epoch 3/3\n",
      "40/40 [==============================] - 5s 115ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0025 - factorized_top_k/top_5_categorical_accuracy: 0.0202 - factorized_top_k/top_10_categorical_accuracy: 0.0404 - factorized_top_k/top_50_categorical_accuracy: 0.1768 - factorized_top_k/top_100_categorical_accuracy: 0.3097 - loss: 13676.4487 - regularization_loss: 0.0000e+00 - total_loss: 13676.4487\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'user_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'timestamp': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=int64>}. Consider rewriting this model with the Functional API.\n",
      "40/40 [==============================] - 5s 114ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0044 - factorized_top_k/top_5_categorical_accuracy: 0.0320 - factorized_top_k/top_10_categorical_accuracy: 0.0609 - factorized_top_k/top_50_categorical_accuracy: 0.2263 - factorized_top_k/top_100_categorical_accuracy: 0.3665 - loss: 13363.9087 - regularization_loss: 0.0000e+00 - total_loss: 13363.9087\n",
      "5/5 [==============================] - 1s 170ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0011 - factorized_top_k/top_5_categorical_accuracy: 0.0104 - factorized_top_k/top_10_categorical_accuracy: 0.0228 - factorized_top_k/top_50_categorical_accuracy: 0.1293 - factorized_top_k/top_100_categorical_accuracy: 0.2476 - loss: 30672.5664 - regularization_loss: 0.0000e+00 - total_loss: 30672.5664\n",
      "Top-100 accuracy (train): 0.37.\n",
      "Top-100 accuracy (test): 0.25.\n"
     ]
    }
   ],
   "source": [
    "model = MovielensModel(use_timestamps=True)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
    "\n",
    "model.fit(cached_train, epochs=3)\n",
    "\n",
    "train_accuracy = model.evaluate(\n",
    "    cached_train, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"]\n",
    "\n",
    "test_accuracy = model.evaluate(\n",
    "    cached_test, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"]\n",
    "\n",
    "print(f\"Top-100 accuracy (train): {train_accuracy:.2f}.\")\n",
    "print(f\"Top-100 accuracy (test): {test_accuracy:.2f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 5s 114ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0028 - factorized_top_k/top_5_categorical_accuracy: 0.0239 - factorized_top_k/top_10_categorical_accuracy: 0.0472 - factorized_top_k/top_50_categorical_accuracy: 0.1896 - factorized_top_k/top_100_categorical_accuracy: 0.3160 - loss: 13678.8459 - regularization_loss: 0.0000e+00 - total_loss: 13678.8459\n"
     ]
    }
   ],
   "source": [
    "raw_acc = model.evaluate(cached_train, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K categorical accuracy: how often the true candidate is in the top K candidates for a given query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'factorized_top_k/top_100_categorical_accuracy': 0.31603750586509705,\n",
      " 'factorized_top_k/top_10_categorical_accuracy': 0.047187499701976776,\n",
      " 'factorized_top_k/top_1_categorical_accuracy': 0.0027874999213963747,\n",
      " 'factorized_top_k/top_50_categorical_accuracy': 0.18963749706745148,\n",
      " 'factorized_top_k/top_5_categorical_accuracy': 0.023887500166893005,\n",
      " 'loss': 557.4373168945312,\n",
      " 'regularization_loss': 0,\n",
      " 'total_loss': 557.4373168945312}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(raw_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
