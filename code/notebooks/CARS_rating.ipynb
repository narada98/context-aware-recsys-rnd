{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_recommenders as tfrs \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "ratings_raw = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
    "ratings = ratings_raw.map(lambda x: {\n",
    "    \"movie_title\" : x['movie_title'],\n",
    "    'timestamp' : x['timestamp'],\n",
    "    'user_id': x['user_id']\n",
    "    })\n",
    "\n",
    "\n",
    "movies_raw = tfds.load(\"movielens/100k-movies\", split=\"train\")\n",
    "movies = movies_raw.map(lambda x: {\n",
    "    'movie_title' : x['movie_title']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset element_spec={'movie_title': TensorSpec(shape=(), dtype=tf.string, name=None)}>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(movies.as_numpy_iterator())\n",
    "movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need these to initialize embedding layers in future steps\n",
    "\n",
    "unique_users = np.unique(np.concatenate(list(ratings.map(lambda x: x['user_id']).batch(1000))))\n",
    "unique_items = np.unique(np.concatenate(list(movies.map(lambda x: x['movie_title']).batch(1000))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need these to initialize timestamp embedding layers in future steps\n",
    "\n",
    "timestamps = np.concatenate(list(ratings.map(lambda x: x[\"timestamp\"]).batch(100)))\n",
    "\n",
    "max_timestamp = timestamps.max()\n",
    "min_timestamp = timestamps.min()\n",
    "\n",
    "timestamp_buckets = np.linspace(\n",
    "    min_timestamp, max_timestamp, num=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "this handles embedding user Identifiers and contextual data.\n",
    "time stamp is used as the contexual information here.\n",
    "using timestamp is \n",
    "'''\n",
    "\n",
    "class UserModel(tf.keras.Model):\n",
    "    def __init__(self, use_timestamp):\n",
    "        super().__init__()\n",
    "\n",
    "        self.use_timestamp = use_timestamp\n",
    "\n",
    "        self.embed_user_id = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(\n",
    "                vocabulary = unique_users,\n",
    "                mask_token =None\n",
    "            ),\n",
    "            tf.keras.layers.Embedding(\n",
    "                input_dim = len(unique_users)+1,\n",
    "                output_dim = 32\n",
    "            )\n",
    "        ])\n",
    "\n",
    "        if self.use_timestamp:\n",
    "            self.embed_timestamp = tf.keras.Sequential([\n",
    "                tf.keras.layers.Discretization(\n",
    "                    bin_boundaries = list(timestamp_buckets)\n",
    "                ),\n",
    "\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim = len(list(timestamp_buckets))+1 ,\n",
    "                    output_dim = 32\n",
    "                )\n",
    "            ])\n",
    "\n",
    "            self.normalize_timestamp = tf.keras.layers.Normalization(\n",
    "                axis = None #calcuate a scaler mean and variance \n",
    "            )\n",
    "            self.normalize_timestamp.adapt(timestamps)\n",
    "\n",
    "    \n",
    "    def call(self, inputs):\n",
    "\n",
    "        if self.use_timestamp:\n",
    "            user_id_embed = self.embed_user_id(inputs['user_id'])\n",
    "            timestamp_embed = self.embed_timestamp(inputs['timestamp'])\n",
    "            norm_timestamp = tf.reshape(self.normalize_timestamp(inputs['timestamp']), (-1,1)) #(-1,1) means first dimension to be infered\n",
    "\n",
    "            return tf.concat([user_id_embed, timestamp_embed, norm_timestamp], axis = 1) #concatenate vertically\n",
    "            \n",
    "        return self.embed_user_id(inputs['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "this handles embedding item Identifiers and contextual data.\n",
    "movie title itself is used as the contexual information here.\n",
    "using timestamp is \n",
    "'''\n",
    "\n",
    "class ItemModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.max_tokens = 10000\n",
    "\n",
    "        self.embed_item_id = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(\n",
    "                vocabulary = unique_items,\n",
    "                mask_token =None\n",
    "            ),\n",
    "            tf.keras.layers.Embedding(\n",
    "                input_dim = len(unique_items)+1,\n",
    "                output_dim = 32\n",
    "            )\n",
    "        ])\n",
    "\n",
    "\n",
    "        self.textvectorizer = tf.keras.layers.TextVectorization(\n",
    "            max_tokens = self.max_tokens\n",
    "        )\n",
    "\n",
    "        self.embed_item_title = tf.keras.Sequential([\n",
    "            self.textvectorizer,\n",
    "\n",
    "            tf.keras.layers.Embedding(\n",
    "                input_dim = self.max_tokens,\n",
    "                output_dim = 32,\n",
    "                mask_zero = True\n",
    "            ),\n",
    "\n",
    "            tf.keras.layers.GlobalAveragePooling1D() # reduces dimensionality to 1d (embedding layer embeddeds each word in a title one by one)\n",
    "        ])\n",
    "\n",
    "        self.textvectorizer.adapt(unique_items)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "\n",
    "        return tf.concat([\n",
    "            self.embed_item_id(inputs['movie_title']),\n",
    "            self.embed_item_title(inputs['movie_title'])\n",
    "        ],\n",
    "        axis = 1)\n",
    "        \n",
    "        # return self.embed_item_title(inputs['movie_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_item = next(movies.batch(10).take(1).as_numpy_iterator())\n",
    "# test_user = next(ratings.batch(10).take(1).as_numpy_iterator())\n",
    "# # test_item['movie_title']\n",
    "# item_model = ItemModel()\n",
    "# user_model = UserModel(use_timestamp=True)\n",
    "\n",
    "# user_out = user_model(test_user)\n",
    "# item_out = item_model(test_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenated_tensor = tf.concat([user_out, item_out], axis=1)\n",
    "# concatenated_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(ratings_raw.batch(10).take(1).as_numpy_iterator())\n",
    "# next(ratings_raw.take(1).as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RatingModel(tf.keras.Model):\n",
    "    def __init__(self, use_timestamp):\n",
    "        super().__init__()\n",
    "        self.use_timestamp = use_timestamp\n",
    "        self.user_model = UserModel(use_timestamp= self.use_timestamp)\n",
    "        self.item_model = ItemModel()\n",
    "\n",
    "        self.rating_NN = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(254, activation = 'relu'),\n",
    "            tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "            tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        user_vec = self.user_model(inputs)\n",
    "        item_vec = self.item_model(inputs)\n",
    "\n",
    "        return self.rating_NN(tf.concat([user_vec, item_vec], axis = 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8192, 1), dtype=float32, numpy=\n",
       "array([[0.01499823],\n",
       "       [0.03705404],\n",
       "       [0.09719963],\n",
       "       ...,\n",
       "       [0.06178984],\n",
       "       [0.01390735],\n",
       "       [0.02128595]], dtype=float32)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_model = RatingModel(use_timestamp = True)\n",
    "rating_model(test_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class recommender(tfrs.models.Model):\n",
    "    def __init__(self, use_timestamp):\n",
    "        super().__init__()\n",
    "\n",
    "        self.use_timestamp = use_timestamp\n",
    "        self.rating_model = RatingModel(use_timestamp = self.use_timestamp)\n",
    "\n",
    "        self.task = tfrs.tasks.Ranking(\n",
    "            loss = tf.keras.losses.MeanAbsoluteError(),\n",
    "            metrics = [tf.keras.metrics.RootMeanSquaredError()]\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.rating_model(inputs)\n",
    "\n",
    "    def compute_loss(self, inputs, training=False): \n",
    "        \n",
    "        # rating_pred = self.rating_model(inputs)\n",
    "        rating_pred = self(inputs)\n",
    "\n",
    "        return self.task(\n",
    "            label = inputs['user_rating'],\n",
    "            predictions = rating_pred\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Text\n",
    "\n",
    "class MovielensModel(tfrs.models.Model):\n",
    "\n",
    "  def __init__(self, use_timestamp):\n",
    "    super().__init__()\n",
    "    self.use_timestamp = use_timestamp\n",
    "    self.ranking_model: tf.keras.Model = RatingModel(use_timestamp = self.use_timestamp)\n",
    "    self.task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "      loss = tf.keras.losses.MeanSquaredError(),\n",
    "      metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    "    )\n",
    "\n",
    "  def call(self, features: Dict[str, tf.Tensor]) -> tf.Tensor:\n",
    "    return self.ranking_model(\n",
    "        (features[\"user_id\"], features[\"movie_title\"]))\n",
    "\n",
    "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "    labels = features.pop(\"user_rating\")\n",
    "\n",
    "    rating_predictions = self(features)\n",
    "\n",
    "    # The task computes the loss and the metrics.\n",
    "    return self.task(labels=labels, predictions=rating_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative\n",
    "\n",
    "ratings_1 = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
    "\n",
    "ratings_1 = ratings_1.map(lambda x: {\n",
    "    \"movie_title\": x[\"movie_title\"],\n",
    "    \"user_id\": x[\"user_id\"],\n",
    "    \"user_rating\": x[\"user_rating\"],\n",
    "    \"timestamp\": x[\"timestamp\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "shuffled = ratings_1.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(80_000)\n",
    "test = shuffled.skip(80_000).take(20_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'movie_title': array([b'Brazil (1985)', b'Dave (1993)', b\"Muriel's Wedding (1994)\", ...,\n",
       "        b'Flirting With Disaster (1996)', b'Gandhi (1982)',\n",
       "        b'Muppet Treasure Island (1996)'], dtype=object),\n",
       " 'user_id': array([b'387', b'389', b'911', ..., b'643', b'537', b'82'], dtype=object),\n",
       " 'user_rating': array([5., 4., 5., ..., 4., 4., 1.], dtype=float32),\n",
       " 'timestamp': array([886479771, 880087850, 892839846, ..., 891447696, 886031860,\n",
       "        884714456], dtype=int64)}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_row = next(cached_train.take(1).as_numpy_iterator())\n",
    "test_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\bpadmin\\anaconda3\\envs\\tensorflow_cuda\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\bpadmin\\anaconda3\\envs\\tensorflow_cuda\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\bpadmin\\anaconda3\\envs\\tensorflow_cuda\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\bpadmin\\anaconda3\\envs\\tensorflow_cuda\\lib\\site-packages\\tensorflow_recommenders\\models\\base.py\", line 68, in train_step\n        loss = self.compute_loss(inputs, training=True)\n    File \"C:\\Users\\naradaw\\AppData\\Local\\Temp\\ipykernel_43080\\3740315027.py\", line 21, in compute_loss\n        rating_predictions = self(features)\n    File \"c:\\Users\\bpadmin\\anaconda3\\envs\\tensorflow_cuda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\naradaw\\AppData\\Local\\Temp\\__autograph_generated_filecg9lbgf1.py\", line 12, in tf__call\n        retval_ = ag__.converted_call(ag__.ld(self).ranking_model, ((ag__.ld(features)['user_id'], ag__.ld(features)['movie_title']),), None, fscope)\n    File \"C:\\Users\\naradaw\\AppData\\Local\\Temp\\__autograph_generated_filenvuhzovw.py\", line 10, in tf__call\n        user_vec = ag__.converted_call(ag__.ld(self).user_model, (ag__.ld(inputs),), None, fscope)\n    File \"C:\\Users\\naradaw\\AppData\\Local\\Temp\\__autograph_generated_filehshrryen.py\", line 41, in tf__call\n        ag__.if_stmt(ag__.ld(self).use_timestamp, if_body, else_body, get_state, set_state, ('do_return', 'retval_'), 2)\n    File \"C:\\Users\\naradaw\\AppData\\Local\\Temp\\__autograph_generated_filehshrryen.py\", line 20, in if_body\n        user_id_embed = ag__.converted_call(ag__.ld(self).embed_user_id, (ag__.ld(inputs)['user_id'],), None, fscope)\n\n    TypeError: Exception encountered when calling layer \"movielens_model_1\" \"                 f\"(type MovielensModel).\n    \n    in user code:\n    \n        File \"C:\\Users\\naradaw\\AppData\\Local\\Temp\\ipykernel_43080\\3740315027.py\", line 16, in call  *\n            (features[\"user_id\"], features[\"movie_title\"]))\n        File \"c:\\Users\\bpadmin\\anaconda3\\envs\\tensorflow_cuda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"C:\\Users\\naradaw\\AppData\\Local\\Temp\\__autograph_generated_filenvuhzovw.py\", line 10, in tf__call\n            user_vec = ag__.converted_call(ag__.ld(self).user_model, (ag__.ld(inputs),), None, fscope)\n        File \"C:\\Users\\naradaw\\AppData\\Local\\Temp\\__autograph_generated_filehshrryen.py\", line 41, in tf__call\n            ag__.if_stmt(ag__.ld(self).use_timestamp, if_body, else_body, get_state, set_state, ('do_return', 'retval_'), 2)\n        File \"C:\\Users\\naradaw\\AppData\\Local\\Temp\\__autograph_generated_filehshrryen.py\", line 20, in if_body\n            user_id_embed = ag__.converted_call(ag__.ld(self).embed_user_id, (ag__.ld(inputs)['user_id'],), None, fscope)\n    \n        TypeError: Exception encountered when calling layer \"rating_model_7\" \"                 f\"(type RatingModel).\n        \n        in user code:\n        \n            File \"C:\\Users\\naradaw\\AppData\\Local\\Temp\\ipykernel_43080\\1993724450.py\", line 16, in call  *\n                user_vec = self.user_model(inputs)\n            File \"c:\\Users\\bpadmin\\anaconda3\\envs\\tensorflow_cuda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n                raise e.with_traceback(filtered_tb) from None\n            File \"C:\\Users\\naradaw\\AppData\\Local\\Temp\\__autograph_generated_filehshrryen.py\", line 41, in tf__call\n                ag__.if_stmt(ag__.ld(self).use_timestamp, if_body, else_body, get_state, set_state, ('do_return', 'retval_'), 2)\n            File \"C:\\Users\\naradaw\\AppData\\Local\\Temp\\__autograph_generated_filehshrryen.py\", line 20, in if_body\n                user_id_embed = ag__.converted_call(ag__.ld(self).embed_user_id, (ag__.ld(inputs)['user_id'],), None, fscope)\n        \n            TypeError: Exception encountered when calling layer \"user_model_7\" \"                 f\"(type UserModel).\n            \n            in user code:\n            \n                File \"C:\\Users\\naradaw\\AppData\\Local\\Temp\\ipykernel_43080\\2174534949.py\", line 45, in call  *\n                    user_id_embed = self.embed_user_id(inputs['user_id'])\n            \n                TypeError: tuple indices must be integers or slices, not str\n            \n            \n            Call arguments received by layer \"user_model_7\" \"                 f\"(type UserModel):\n              • inputs=('tf.Tensor(shape=(None,), dtype=string)', 'tf.Tensor(shape=(None,), dtype=string)')\n        \n        \n        Call arguments received by layer \"rating_model_7\" \"                 f\"(type RatingModel):\n          • inputs=('tf.Tensor(shape=(None,), dtype=string)', 'tf.Tensor(shape=(None,), dtype=string)')\n    \n    \n    Call arguments received by layer \"movielens_model_1\" \"                 f\"(type MovielensModel):\n      • features={'movie_title': 'tf.Tensor(shape=(None,), dtype=string)', 'user_id': 'tf.Tensor(shape=(None,), dtype=string)', 'timestamp': 'tf.Tensor(shape=(None,), dtype=int64)'}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[74], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m reco_model \u001b[38;5;241m=\u001b[39m MovielensModel(use_timestamp\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      2\u001b[0m reco_model\u001b[38;5;241m.\u001b[39mcompile(optimizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam())\n\u001b[1;32m----> 4\u001b[0m \u001b[43mreco_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcached_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bpadmin\\anaconda3\\envs\\tensorflow_cuda\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileqq50n034.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bpadmin\\anaconda3\\envs\\tensorflow_cuda\\lib\\site-packages\\tensorflow_recommenders\\models\\base.py:68\u001b[0m, in \u001b[0;36mModel.train_step\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Custom train step using the `compute_loss` method.\"\"\"\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[1;32m---> 68\u001b[0m   loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(inputs, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     70\u001b[0m   \u001b[38;5;66;03m# Handle regularization losses as well.\u001b[39;00m\n\u001b[0;32m     71\u001b[0m   regularization_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlosses)\n",
      "Cell \u001b[1;32mIn[73], line 21\u001b[0m, in \u001b[0;36mMovielensModel.compute_loss\u001b[1;34m(self, features, training)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_loss\u001b[39m(\u001b[38;5;28mself\u001b[39m, features: Dict[Text, tf\u001b[38;5;241m.\u001b[39mTensor], training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m tf\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m     19\u001b[0m   labels \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_rating\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 21\u001b[0m   rating_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m   \u001b[38;5;66;03m# The task computes the loss and the metrics.\u001b[39;00m\n\u001b[0;32m     24\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask(labels\u001b[38;5;241m=\u001b[39mlabels, predictions\u001b[38;5;241m=\u001b[39mrating_predictions)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filecg9lbgf1.py:12\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     11\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mranking_model, ((ag__\u001b[38;5;241m.\u001b[39mld(features)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m], ag__\u001b[38;5;241m.\u001b[39mld(features)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmovie_title\u001b[39m\u001b[38;5;124m'\u001b[39m]),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filenvuhzovw.py:10\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m      8\u001b[0m do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m      9\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[1;32m---> 10\u001b[0m user_vec \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39muser_model, (ag__\u001b[38;5;241m.\u001b[39mld(inputs),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     11\u001b[0m item_vec \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mitem_model, (ag__\u001b[38;5;241m.\u001b[39mld(inputs),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filehshrryen.py:41\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     39\u001b[0m user_id_embed \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id_embed\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     40\u001b[0m norm_timestamp \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnorm_timestamp\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 41\u001b[0m ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39muse_timestamp, if_body, else_body, get_state, set_state, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdo_return\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mretval_\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fscope\u001b[38;5;241m.\u001b[39mret(retval_, do_return)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filehshrryen.py:20\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.if_body\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mif_body\u001b[39m():\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mnonlocal\u001b[39;00m do_return, retval_\n\u001b[1;32m---> 20\u001b[0m     user_id_embed \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39membed_user_id, (\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muser_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m,), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     21\u001b[0m     timestamp_embed \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39membed_timestamp, (ag__\u001b[38;5;241m.\u001b[39mld(inputs)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m],), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     22\u001b[0m     norm_timestamp \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mreshape, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mnormalize_timestamp, (ag__\u001b[38;5;241m.\u001b[39mld(inputs)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m],), \u001b[38;5;28;01mNone\u001b[39;00m, fscope), (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "\u001b[1;31mTypeError\u001b[0m: in user code:\n\n    File \"c:\\Users\\bpadmin\\anaconda3\\envs\\tensorflow_cuda\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\bpadmin\\anaconda3\\envs\\tensorflow_cuda\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\bpadmin\\anaconda3\\envs\\tensorflow_cuda\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\bpadmin\\anaconda3\\envs\\tensorflow_cuda\\lib\\site-packages\\tensorflow_recommenders\\models\\base.py\", line 68, in train_step\n        loss = self.compute_loss(inputs, training=True)\n    File \"C:\\Users\\naradaw\\AppData\\Local\\Temp\\ipykernel_43080\\3740315027.py\", line 21, in compute_loss\n        rating_predictions = self(features)\n    File \"c:\\Users\\bpadmin\\anaconda3\\envs\\tensorflow_cuda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\naradaw\\AppData\\Local\\Temp\\__autograph_generated_filecg9lbgf1.py\", line 12, in tf__call\n        retval_ = ag__.converted_call(ag__.ld(self).ranking_model, ((ag__.ld(features)['user_id'], ag__.ld(features)['movie_title']),), None, fscope)\n    File \"C:\\Users\\naradaw\\AppData\\Local\\Temp\\__autograph_generated_filenvuhzovw.py\", line 10, in tf__call\n        user_vec = ag__.converted_call(ag__.ld(self).user_model, (ag__.ld(inputs),), None, fscope)\n    File \"C:\\Users\\naradaw\\AppData\\Local\\Temp\\__autograph_generated_filehshrryen.py\", line 41, in tf__call\n        ag__.if_stmt(ag__.ld(self).use_timestamp, if_body, else_body, get_state, set_state, ('do_return', 'retval_'), 2)\n    File \"C:\\Users\\naradaw\\AppData\\Local\\Temp\\__autograph_generated_filehshrryen.py\", line 20, in if_body\n        user_id_embed = ag__.converted_call(ag__.ld(self).embed_user_id, (ag__.ld(inputs)['user_id'],), None, fscope)\n\n    TypeError: Exception encountered when calling layer \"movielens_model_1\" \"                 f\"(type MovielensModel).\n    \n    in user code:\n    \n        File \"C:\\Users\\naradaw\\AppData\\Local\\Temp\\ipykernel_43080\\3740315027.py\", line 16, in call  *\n            (features[\"user_id\"], features[\"movie_title\"]))\n        File \"c:\\Users\\bpadmin\\anaconda3\\envs\\tensorflow_cuda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"C:\\Users\\naradaw\\AppData\\Local\\Temp\\__autograph_generated_filenvuhzovw.py\", line 10, in tf__call\n            user_vec = ag__.converted_call(ag__.ld(self).user_model, (ag__.ld(inputs),), None, fscope)\n        File \"C:\\Users\\naradaw\\AppData\\Local\\Temp\\__autograph_generated_filehshrryen.py\", line 41, in tf__call\n            ag__.if_stmt(ag__.ld(self).use_timestamp, if_body, else_body, get_state, set_state, ('do_return', 'retval_'), 2)\n        File \"C:\\Users\\naradaw\\AppData\\Local\\Temp\\__autograph_generated_filehshrryen.py\", line 20, in if_body\n            user_id_embed = ag__.converted_call(ag__.ld(self).embed_user_id, (ag__.ld(inputs)['user_id'],), None, fscope)\n    \n        TypeError: Exception encountered when calling layer \"rating_model_7\" \"                 f\"(type RatingModel).\n        \n        in user code:\n        \n            File \"C:\\Users\\naradaw\\AppData\\Local\\Temp\\ipykernel_43080\\1993724450.py\", line 16, in call  *\n                user_vec = self.user_model(inputs)\n            File \"c:\\Users\\bpadmin\\anaconda3\\envs\\tensorflow_cuda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n                raise e.with_traceback(filtered_tb) from None\n            File \"C:\\Users\\naradaw\\AppData\\Local\\Temp\\__autograph_generated_filehshrryen.py\", line 41, in tf__call\n                ag__.if_stmt(ag__.ld(self).use_timestamp, if_body, else_body, get_state, set_state, ('do_return', 'retval_'), 2)\n            File \"C:\\Users\\naradaw\\AppData\\Local\\Temp\\__autograph_generated_filehshrryen.py\", line 20, in if_body\n                user_id_embed = ag__.converted_call(ag__.ld(self).embed_user_id, (ag__.ld(inputs)['user_id'],), None, fscope)\n        \n            TypeError: Exception encountered when calling layer \"user_model_7\" \"                 f\"(type UserModel).\n            \n            in user code:\n            \n                File \"C:\\Users\\naradaw\\AppData\\Local\\Temp\\ipykernel_43080\\2174534949.py\", line 45, in call  *\n                    user_id_embed = self.embed_user_id(inputs['user_id'])\n            \n                TypeError: tuple indices must be integers or slices, not str\n            \n            \n            Call arguments received by layer \"user_model_7\" \"                 f\"(type UserModel):\n              • inputs=('tf.Tensor(shape=(None,), dtype=string)', 'tf.Tensor(shape=(None,), dtype=string)')\n        \n        \n        Call arguments received by layer \"rating_model_7\" \"                 f\"(type RatingModel):\n          • inputs=('tf.Tensor(shape=(None,), dtype=string)', 'tf.Tensor(shape=(None,), dtype=string)')\n    \n    \n    Call arguments received by layer \"movielens_model_1\" \"                 f\"(type MovielensModel):\n      • features={'movie_title': 'tf.Tensor(shape=(None,), dtype=string)', 'user_id': 'tf.Tensor(shape=(None,), dtype=string)', 'timestamp': 'tf.Tensor(shape=(None,), dtype=int64)'}\n"
     ]
    }
   ],
   "source": [
    "reco_model = MovielensModel(use_timestamp= True)\n",
    "reco_model.compile(optimizer = tf.keras.optimizers.Adam())\n",
    "\n",
    "reco_model.fit(cached_train, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'movie_title': b\"One Flew Over the Cuckoo's Nest (1975)\",\n",
       " 'timestamp': 879024327,\n",
       " 'user_id': b'138'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = next(ratings.take(1).as_numpy_iterator())\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('movie_title', 'timestamp', 'user_id')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o, t, tr = test\n",
    "o, t, tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tensor1 = tf.constant([[[1, 2],\n",
    "                       [3, 4]],\n",
    "                       [[5, 6],\n",
    "                       [7, 8]]])\n",
    "\n",
    "\n",
    "tensor2 = tf.constant([[[5, 6],\n",
    "                       [7, 8]],\n",
    "                       [[1, 2],\n",
    "                       [3, 4]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 4), dtype=int32, numpy=\n",
       "array([[[1, 2, 5, 6],\n",
       "        [3, 4, 7, 8]],\n",
       "\n",
       "       [[5, 6, 1, 2],\n",
       "        [7, 8, 3, 4]]])>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated_tensor = tf.concat([tensor1, tensor2], axis=2)\n",
    "concatenated_tensor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
